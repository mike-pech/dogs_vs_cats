{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./IMDB Dataset.csv\")\n",
    "data.replace(to_replace={\"sentiment\": {\"negative\": 0, \"positive\": 1}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_quoted = re.compile(r\"\\\".*?\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем версию без наименований в ковычках. Их исключение повышает точность моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = nltk.corpus.names.words()\n",
    "cleanedup_data = data.copy(deep=True)\n",
    "cleanedup_data[\"review\"] = cleanedup_data[\"review\"].apply(\n",
    "    lambda r: re.sub(rm_quoted, \"\", r.replace(\"<br />\", \"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также лемматизируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrStopwords = stopwords.words(\"english\")\n",
    "arrStopwords.extend([\"br\", \"<br>\", \"<br />\"])\n",
    "lemm_arr = []\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for r in data.iterrows():\n",
    "    rev = r[1][\"review\"]\n",
    "\n",
    "    rev_no_quotes = re.sub(rm_quoted, \"\", rev)\n",
    "    rev_tok = word_tokenize(rev_no_quotes)\n",
    "    rev_tok = [w.lower() for w in rev_tok]\n",
    "\n",
    "    rev_tok_filtered = [w for w in rev_tok if not w in arrStopwords]\n",
    "    rev_tok_filtered = [w for w in rev_tok_filtered if w.isalpha()]\n",
    "\n",
    "    rev_tok_lemmatized = np.array([wnl.lemmatize(w) for w in rev_tok_filtered])\n",
    "\n",
    "    # reviews_tok_arr.append(rev_tok_filtered)\n",
    "    lemm_arr.append((rev_tok_lemmatized, r[1][\"sentiment\"]))\n",
    "\n",
    "lemm_data = pd.DataFrame(columns=[\"reviews\", \"sentiment\"], data=lemm_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_results = {\"raw\" : data, \"cleaned\" : cleanedup_data, \"lemmatized\" : lemm_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analyzer встроенный в NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В NLTK есть предобученный определитель настроения называемый VADER. Можно решить задачу при помощи него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\danil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 69.63%\n"
     ]
    }
   ],
   "source": [
    "vader_predictions = []\n",
    "\n",
    "for r in cleanedup_data.iterrows():\n",
    "    rev = r[1][\"review\"]\n",
    "\n",
    "    vader_predictions.append(\n",
    "        0 if vader.polarity_scores(rev)[\"compound\"] < 0 else 1\n",
    "    )\n",
    "\n",
    "print(f\"Точность: {accuracy_score(cleanedup_data['sentiment'], vader_predictions) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже так можно добится точности в районе 70%. На несколько процентов точность можно повысить, если добавить дополнительные признаки и использовать классификаторы из scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала получим списоки отрицательных и положительных слов из корпуса NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_en = nltk.corpus.stopwords.words(\"english\")\n",
    "stopword_en.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in stopword_en:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом выберем самые часто встречающиеся положительные и отрицательные леммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive_lem = {wnl.lemmatize(w) for w, count in positive_fd.most_common(100)}\n",
    "top_100_negative_lem = {wnl.lemmatize(w) for w, count in negative_fd.most_common(100)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим классифаеры из scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для экстракции признаков. Она собирает количество негативных и позитивных слов, а также значения выдаваемые VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    pos_word_count = 0\n",
    "    neg_word_count = 0\n",
    "\n",
    "    for r in wnl.lemmatize(text):\n",
    "        for w in r:\n",
    "            if w in top_100_negative_lem:\n",
    "                neg_word_count += 1\n",
    "            elif w in top_100_positive_lem:\n",
    "                pos_word_count += 1\n",
    "\n",
    "    vader_scores = vader.polarity_scores(text)\n",
    "    \n",
    "    features[\"compound\"] = vader_scores[\"compound\"] + 1\n",
    "    features[\"neg\"] = vader_scores[\"neg\"]\n",
    "    features[\"pos\"] = vader_scores[\"pos\"]\n",
    "    features[\"pos_word_count\"] = pos_word_count\n",
    "    features[\"neg_word_count\"] = neg_word_count\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собирём признаки для всего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist = []\n",
    "feature_names = list(extract_features(\"I like pickles\"))\n",
    "data_column_names = feature_names + [\"sentiment\"]\n",
    "\n",
    "for r in cleanedup_data.iterrows():\n",
    "    r_features_dict = extract_features(r[1][\"review\"])\n",
    "    r_features_dict[\"sentiment\"] = r[1][\"sentiment\"]\n",
    "    featurelist.append(r_features_dict)\n",
    "\n",
    "features_df = pd.DataFrame(data=featurelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем признаки как вводный массив для разных моделей sklearn. Как видим точность некоторых моделей привосходит точность VADER самого по себе. Теоретически можно попробовать вывести ещё больше значимых признаков из текстов данного датасета и увеличить тем самым точность ещё выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.91% - BernoulliNB\n",
      "70.11% - ComplementNB\n",
      "70.09% - MultinomialNB\n",
      "69.47% - KNeighborsClassifier\n",
      "63.65% - DecisionTreeClassifier\n",
      "70.15% - RandomForestClassifier\n",
      "72.37% - MLPClassifier\n",
      "72.49% - AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(features_df, train_size=0.85)\n",
    "\n",
    "for name, sklearn_classifier in classifiers.items():\n",
    "    cls = sklearn_classifier\n",
    "\n",
    "    x_train = train_data.drop(columns=[\"sentiment\"])\n",
    "    y_train = train_data[\"sentiment\"]\n",
    "\n",
    "    x_test = test_data.drop(columns=[\"sentiment\"])\n",
    "    y_test = test_data[\"sentiment\"]\n",
    "\n",
    "    model = cls.fit(X=x_train, y=y_train)\n",
    "\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(F\"{accuracy:.2%} - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главным приемуществом данного метода является его скорость. Обработать весь датасет при помощи VADER можно за секунды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 33s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 1min 33s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n1 -r1 -o\n",
    "dummy_predictions = []\n",
    "for r in cleanedup_data.iterrows():\n",
    "    rev = r[1][\"review\"]\n",
    "\n",
    "    dummy_predictions.append(\n",
    "        0 if vader.polarity_scores(rev)[\"compound\"] < 0 else 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_worktime = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **Главным приемуществом данного метода является его скорость. Обработать весь датасет при помощи VADER можно за 93.43 секунды**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"### **Главным приемуществом данного метода является его скорость. Обработать весь датасет при помощи VADER можно за {vader_worktime.average:.2f} секунды**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели с Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для анализа можно использовать модели предтренированные работоприятные с Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
